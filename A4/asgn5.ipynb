{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>COMP4680/8650: Advanced Topics in Machine Learning</h1>\n",
    "<h2>Assignment #5: Programming Assignment</h2>\n",
    "Semester 2, 2023<br>\n",
    "</center>\n",
    "    \n",
    "**Due**: 11:55pm on Sunday 22 October, 2023.<br>\n",
    "\n",
    "Submit solutions as a single Jupyter Notebook via Wattle. Make sure that your name and student ID appears in the section below. You may not work with any other person in completing this assignment. You must acknowledge any non-course texts or online material used.\n",
    "\n",
    "---\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "**Marking Rubric.** Each section is graded out of 4 marks and the assignment mark is computed as the average over both sections. Grading is as follows:\n",
    "\n",
    "* 4: Perfect answers. Completely correct. Shows all steps. Clearly laid out.\n",
    "* 3: Correct or mostly correct answers. Missing steps or minor notation/layout errors.\n",
    "* 2: Did not arrive at correct answer for some questions but on the right track.\n",
    "* 1: Attempted most questions. Made partial progress but includes major mistakes.\n",
    "* 0: Did not attempt any question.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** ``(enter your full name here)``\n",
    "<br>\n",
    "**Student ID:** ``(enter your student ID here)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This assignment gives you an opportunity to implement and experiment with different optimisation algorithms for solving convex (and nonconvex) optimisation problems. We will provide you with starter code in Python. The second part of the assignment will make use of the PyTorch deep learning library, which can be downloaded from https://pytorch.org/. Follow the installation instructions (for the stable release, v2.0.1 at time of writing), being sure to install both `pytorch` and `torchvision`.\n",
    "Browse through some of the PyTorch user documentation and tutorials.\n",
    "\n",
    "**Run all code blocks from start to end (`Restart & Run All`) and then save your Jupyter Notebook\n",
    "before submitting your assignment to ensure everything works as expected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:05.599147Z",
     "start_time": "2023-09-12T12:02:04.771432Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Unconstrained Optimization\n",
    "\n",
    "In this question you will complete an implementation of Newton's method for solving the following unconstrained convex optimization problem,\n",
    "\n",
    "$$\n",
    "    \\text{minimize} \\quad f(x) \\triangleq - \\sum_{i=1}^{n} \\log (1 - x_i^2) - \\sum_{i=1}^{m} \\log (b_i - a_i^T x)\n",
    "$$\n",
    "\n",
    "Data for the problem is generated randomly as\n",
    "\n",
    "$$\n",
    "    A = \\begin{bmatrix} a_1^T \\\\ a_2^T \\\\ \\vdots \\\\ a_m^T \\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\n",
    "    \\quad \\text{and} \\quad\n",
    "    b \\in \\mathbb{R}_{++}^{m}\n",
    "$$\n",
    "\n",
    "Since $b \\succ 0$ we know that $x = 0$ is a feasible point for initialising our optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:05.629374Z",
     "start_time": "2023-09-12T12:02:05.606434Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate a problem instance\n",
    "rnd.seed(4680)\n",
    "\n",
    "m = 1000\n",
    "n = 100\n",
    "A = rnd.randn(m, n)\n",
    "b = rnd.rand(m, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Derive an expression for the gradient $g = \\nabla f(x)$\n",
    "\n",
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Derive an expression for the Hessian $H = \\nabla^2 f(x)$\n",
    "\n",
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Complete functions `objective(x)`, `gradient(x)` and `hessian(x)` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:05.645436Z",
     "start_time": "2023-09-12T12:02:05.632368Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    \"\"\"Returns the value of the objective function at x.\"\"\"\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the objective function. Your function should make use   #\n",
    "    # of the global variables A and b. Don't forget to check whether x is in  #\n",
    "    # the domain of the objective and return inf otherwise.                   #\n",
    "    ###########################################################################\n",
    "    pass\n",
    "\n",
    "\n",
    "def gradient(x):\n",
    "    \"\"\"Returns the gradient of the objective function at x.\"\"\"\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the gradient of the objective function.                 #\n",
    "    ###########################################################################\n",
    "    pass\n",
    "\n",
    "\n",
    "def hessian(x):\n",
    "    \"\"\"Returns the Hessian of the objective function at x.\"\"\"\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the Hessian of the objective function.                  #\n",
    "    ###########################################################################\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Implement the `linesearch(...)` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:05.660860Z",
     "start_time": "2023-09-12T12:02:05.649320Z"
    }
   },
   "outputs": [],
   "source": [
    "def linesearch(f, df, x, dx, alpha=0.3, beta=0.7):\n",
    "    \"\"\"\n",
    "    Implements backtracking line search on function f. See B&V Algorithm 9.2.\n",
    "\n",
    "    :param f: The function being optimized.\n",
    "    :param df: Gradient of the function at x.\n",
    "    :param x: Starting point for line search.\n",
    "    :param dx: Direction of line search.\n",
    "    :param alpha: Line search parameter for stopping criteria.\n",
    "    :param beta: Line search parameter for reducing step size.\n",
    "    :return: Step size t.\n",
    "    \"\"\"\n",
    "\n",
    "    t = 1.0\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the backtracking line search algorithm.                 #\n",
    "    ###########################################################################\n",
    "\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Run the following code block to test your code\n",
    "\n",
    "The implementation of `gradient_descent` and `newton` are provided for you. Both use the `linesearch` function you implemented above for backtracking line search. You simply need to run the code. Scroll to the bottom of the output cell to see a plot of the optimality gap versus iteration number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:06.926237Z",
     "start_time": "2023-09-12T12:02:05.663862Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, f, g, eps=1.0e-6, max_iters=200, alpha=0.3, beta=0.7):\n",
    "    \"\"\"\n",
    "    Implements gradient descent to minimize function f. See B&V Algorithm 9.3.\n",
    "\n",
    "    :param x: Starting point in domain of f.\n",
    "    :param f: The function to be optimized. Returns scalar.\n",
    "    :param g: The gradient function. Returns vector in R^n.\n",
    "    :param eps: Tolerance for stopping.\n",
    "    :param max_iters: Maximum number of iterations for stopping.\n",
    "    :param alpha: Backtracking line search parameter.\n",
    "    :param beta: Backtracking line search parameter.\n",
    "    :return: Optimization path (i.e., array of x's). The last point is the optimal point.\n",
    "    \"\"\"\n",
    "\n",
    "    path = [x.copy()]\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "        # Compute gradient\n",
    "        dx = -1.0 * g(x)\n",
    "\n",
    "        # Stopping criterion\n",
    "        print(\"...iter {}, f(x) = {}\".format(iter, f(x)))\n",
    "        if np.linalg.norm(dx) <= eps:\n",
    "            break\n",
    "\n",
    "        # Line search\n",
    "        t = linesearch(f, g(x), x, dx, alpha, beta)\n",
    "\n",
    "        # Update\n",
    "        x += t * dx\n",
    "        path.append(x.copy())\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def newton(x, f, g, H, eps=1.0e-6, max_iters=200, alpha=0.3, beta=0.7):\n",
    "    \"\"\"\n",
    "    Implements Newton's method to minimize function f. See B&V Algorithm 9.5.\n",
    "\n",
    "    :param x: Starting point in domain of f.\n",
    "    :param f: The function to be optimized. Returns scalar.\n",
    "    :param g: The gradient function. Returns vector in R^n.\n",
    "    :param H: The Hessian function. Returns matrix in R^{n \\times n}.\n",
    "    :param eps: Tolerance for stopping.\n",
    "    :param max_iters: Maximum number of iterations for stopping.\n",
    "    :param alpha: Backtracking line search parameter.\n",
    "    :param beta: Backtracking line search parameter.\n",
    "    :return: Optimization path (i.e., array of x's). The last point is the optimal point.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize optimization path\n",
    "    path = [x.copy()]\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "        # Compute Newton step and decrement\n",
    "        dx = -1.0 * np.linalg.solve(H(x), g(x))\n",
    "        lmd2 = -1.0 * np.dot(g(x).T, dx)\n",
    "\n",
    "        # Stopping criterion\n",
    "        print(\"...iter {}, f(x) = {}\".format(iter, f(x)))\n",
    "        if 0.5 * lmd2 <= eps:\n",
    "            break\n",
    "\n",
    "        # Line search\n",
    "        t = linesearch(f, g(x), x, dx, alpha, beta)\n",
    "\n",
    "        # Update\n",
    "        x += t * dx\n",
    "        path.append(x.copy())\n",
    "\n",
    "    return path\n",
    "\n",
    "# --- test -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# solve using gradient descent\n",
    "gd_path = gradient_descent(np.zeros((n, 1)), objective, gradient)\n",
    "\n",
    "# solve using newton's method\n",
    "nm_path = newton(np.zeros((n, 1)), objective, gradient, hessian)\n",
    "\n",
    "if objective(nm_path[-1]) < objective(gd_path[-1]):\n",
    "    x_star = nm_path[-1]\n",
    "else:\n",
    "    x_star = gd_path[-1]\n",
    "p_star = objective(x_star)\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.semilogy(range(len(gd_path)), [objective(x) - p_star for x in gd_path], lw=2)\n",
    "plt.semilogy(range(len(nm_path)), [objective(x) - p_star for x in nm_path], lw=2)\n",
    "plt.xlabel(\"$k$\"); plt.ylabel(r\"$f(x) - p^\\star$\")\n",
    "plt.legend([\"Gradient Descent\", \"Newton's Method\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f) Implement gradient descent without line search\n",
    "\n",
    "We will implement gradient descent with a fixed step size and decaying step size schedule. This is commonly done when evaluating the function (i.e., performing line search) is expensive. However, the cost is often more iterations of the optimisation algorithm. Pseudo-code for the algorithm is\n",
    "\n",
    "---\n",
    "\n",
    "**given** a starting point $x \\in \\textbf{dom} f$, a starting step size $t > 0$, and decay rate $0 < \\gamma \\leq 1$\n",
    "\n",
    "**repeat**\n",
    "1. $\\Delta x_{nsd} := −\\nabla f(x) / \\|\\nabla f(x)\\|$.\n",
    "2. if $x + t \\Delta x_{nsd}$ feasible, then $x := x + t \\Delta x_{nsd}$.\n",
    "3. $t := \\gamma t$.\n",
    "\n",
    "**until** stopping criterion is satisfied.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:07.317379Z",
     "start_time": "2023-09-12T12:02:06.928189Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent_no_linesearch(x, f, g, eps=1.0e-6, max_iters=500, t=1.0e-3, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Implements gradient descent with fixed step size to minimize function f.\n",
    "\n",
    "    :param x: Starting point in domain of f.\n",
    "    :param f: The function to be optimized. Returns scalar.\n",
    "    :param g: The gradient function. Returns vector in R^n.\n",
    "    :param eps: Tolerance for stopping.\n",
    "    :param max_iters: Maximum number of iterations for stopping.\n",
    "    :param t: Initial step size parameter.\n",
    "    :param gamma: Step size decay schedule (set to 1.0 for fixed step size).\n",
    "    :return: Optimization path (i.e., array of x's). The last point is the optimal point.\n",
    "    \"\"\"\n",
    "\n",
    "    path = [x.copy()]\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement gradient descent with step size schedule. You can use   #\n",
    "    # the `gradient_descent` function above as an example. Don't forget to    #\n",
    "    # ensure that x remains feasible. If x becomes infeasible then do not     #\n",
    "    # take that step. Use `path.append(x.copy())` at the end of your loop to  #\n",
    "    # keep a trace of the optimisation path.                                  #\n",
    "    ###########################################################################    \n",
    "    \n",
    "\n",
    "    \n",
    "    return path\n",
    "\n",
    "# --- test -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# solve using gradient descent with fixed step size\n",
    "gd_fixed = gradient_descent_no_linesearch(np.zeros((n, 1)), objective, gradient, t=1.0e-3)\n",
    "\n",
    "# solve using gradient descent with decaying step size\n",
    "gd_decay = gradient_descent_no_linesearch(np.zeros((n, 1)), objective, gradient, t=5.0e-3, gamma=0.99)\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.semilogy(range(len(gd_path)), [objective(x) - p_star for x in gd_path], lw=2)\n",
    "plt.semilogy(range(len(nm_path)), [objective(x) - p_star for x in nm_path], lw=2)\n",
    "plt.semilogy(range(len(gd_fixed)), [objective(x) - p_star for x in gd_fixed], lw=2)\n",
    "plt.semilogy(range(len(gd_decay)), [objective(x) - p_star for x in gd_decay], lw=2)\n",
    "plt.xlabel(\"$k$\"); plt.ylabel(r\"$f(x) - p^\\star$\")\n",
    "plt.legend([\"Gradient Descent\", \"Newton's Method\", \"Fixed Gradient Descent (t=1e-3)\", \"Decaying Gradient Descent (t=5e-3, gamma=0.99)\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (g) What can you say about the speed of convergence of Newton's method compared to gradient descent? What can you say about line search compared to no line search?\n",
    "\n",
    "*(enter your answer here)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Differentiable Optimisation\n",
    "\n",
    "In this question you will code up a differentiable polynomial fitting function. You will then use bi-level optimisation to update the data so as to achieve certain properties of the solution.\n",
    "\n",
    "Given a dataset ${\\cal D} = \\{(x_i, y_i)\\}_{i=1}^{m}$ we wish to fit an $(n-1)$-th order polynomial function $f_\\theta(x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_{n-1} x^{n-1}$ to the points. We do this by solving a least-squares optimisation problem,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{minimize}_\\theta \\quad \\sum_{i=1}^{m} (f_\\theta(x_i) - y_i)^2\n",
    "\\end{align*}\n",
    "\n",
    "which can be reformulated as a standard least-squares problem as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{minimize}_\\theta \\quad \\|A \\theta - b \\|_2^2\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    " A = \\begin{bmatrix}\n",
    "   1 & x_1 & x_1^2 & \\ldots & x_1^{n-1} \\\\\n",
    "   1 & x_2 & x_2^2 & \\ldots & x_2^{n-1} \\\\\n",
    "   \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "   1 & x_m & x_m^2 & \\ldots & x_m^{n-1} \\\\\n",
    " \\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\n",
    "\\end{align*}\n",
    "\n",
    "and $b = y \\in \\mathbb{R}^m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:42:52.093505Z",
     "start_time": "2023-09-12T23:42:50.137657Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_device_name() if torch.cuda.is_available() else \"No CUDA\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Derive the gradient of $A_{ij}$ with respect to $x_k$\n",
    "\n",
    "This will be useful for calculating the gradient of the loss with respect to $x$ in the code below as\n",
    "$$\n",
    "\\frac{\\text{d} L}{\\text{d} x_k} = \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\frac{\\text{d} L}{\\text{d} A_{ij}} \\frac{\\text{d} A_{ij}}{\\text{d} x_k}.\n",
    "$$\n",
    "The term we want you to compute here is $\\frac{\\text{d} A_{ij}}{\\text{d} x_k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(enter your answer here)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Implement differentiable polynomial fitting\n",
    "\n",
    "Complete the sections marked `TODO` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:42:53.807718Z",
     "start_time": "2023-09-12T23:42:53.786773Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiffPolyFitFcn(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    PyTorch autograd function for differentiable polynomial fitting,\n",
    "\n",
    "        argmin_\\theta \\sum_{i=1}^{m} (f_\\theta(x_i) - y_i)^2\n",
    "\n",
    "    where f(x) = \\theta_1 + \\theta_2 x + ... + \\theta_n x^{n-1}, solved via least-squares fitting.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, X, Y, N=4):\n",
    "        B, M = X.shape\n",
    "        assert Y.shape == X.shape\n",
    "\n",
    "        ###########################################################################\n",
    "        # TODO: Construct the A matrix and b vector for the least-squares problem #\n",
    "        # which will be solved by QR decomposition.                               #\n",
    "        ###########################################################################\n",
    "        A = torch.ones((B, M, N), dtype=X.dtype, device=X.device)\n",
    "        for i in range(1, N):\n",
    "            A[:, :, i] = torch.pow(X, i)\n",
    "        b = Y\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Q, R = torch.linalg.qr(A, mode='reduced')\n",
    "            theta = torch.linalg.solve_triangular(R, torch.bmm(b.view(B, 1, M), Q).view(B, N, 1), upper=True)\n",
    "\n",
    "        # save state for backward pass\n",
    "        ctx.save_for_backward(A, b, theta, R)\n",
    "\n",
    "        # return solution\n",
    "        return theta\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dLdtheta):\n",
    "        # check for None tensors\n",
    "        if dLdtheta is None:\n",
    "            return None, None\n",
    "\n",
    "        # unpack cached tensors\n",
    "        A, b, theta, R = ctx.saved_tensors\n",
    "        B, M, N = A.shape\n",
    "\n",
    "        dLdX, dLdY = None, None\n",
    "\n",
    "        w = torch.linalg.solve_triangular(R, torch.linalg.solve_triangular(torch.transpose(R, 2, 1), dLdtheta, upper=False), upper=True)\n",
    "        Aw = torch.bmm(A, w)\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            r = b.view(B, M, 1) - torch.bmm(A, theta)\n",
    "            dLdA = torch.bmm(r, w.view(B, 1, N)) - torch.bmm(Aw.view(B, M, 1), theta.view(B, 1, N))\n",
    "            \n",
    "            ###########################################################################\n",
    "            # TODO: Compute dLdX from dLdA. Make sure dLdX has size (B, M).           #\n",
    "            ###########################################################################\n",
    "            pass\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            dLdY = Aw.view(B, M)\n",
    "        \n",
    "        # return gradients (None for non-tensor inputs)\n",
    "        return dLdX, dLdY, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Unit Test\n",
    "\n",
    "Run the following unit tests and make sure they pass before proceeding to the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:42:56.283800Z",
     "start_time": "2023-09-12T23:42:56.236812Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "B, M, N = 1, 10, 5\n",
    "fcn = DiffPolyFitFcn.apply\n",
    "\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn((B, M), dtype=torch.double, device=device, requires_grad=True)\n",
    "Y = torch.randn((B, M), dtype=torch.double, device=device, requires_grad=True)\n",
    "\n",
    "test = gradcheck(fcn, (X, Y, N), eps=1e-6, atol=1e-3, rtol=1e-6)\n",
    "print(\"Backward test of DiffPolyFitFcn: {}\".format(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Bi-level Optimisation\n",
    "\n",
    "We now design a bi-level optimisation problem what will adjust the points in ${\\cal D} = \\{(x_i, y_i)\\}$ so that when fitted to a thrid-order polynomial the parameters of the polynomial match a given target, $\\theta^{\\text{target}}$. Formally, the optimisation problem can be written as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\t\\begin{array}{ll}\n",
    "\t\t\\text{minimize} & \\frac{1}{2} \\|\\theta^\\star - \\theta^{\\text{target}}\\|_2^2 \\\\\n",
    "\t\t\\text{subject to} & \\theta^\\star = \\textrm{argmin}_{\\theta} \\; \\sum_{i=1}^{m} (f_\\theta(x_i) - y_i)^2\n",
    "\t\\end{array}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "You have already implemented the lower-level problem in `DiffPolyFitFcn`.\n",
    "\n",
    "Read the code below and make sure you understand it. Run it, then answer the questions in Part (e).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:48:25.824483Z",
     "start_time": "2023-09-12T23:48:23.707609Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(8650)\n",
    "\n",
    "def poly(x, theta):\n",
    "    \"\"\"Evaluate polynomial, f(x) = theta_1 + theta_2 x + ... + theta_n x^{n-1}, at points x.\"\"\"\n",
    "    y = theta[0] * torch.ones_like(x)\n",
    "    for i in range(1, len(theta)):\n",
    "        y += theta[i] * torch.pow(x, i)\n",
    "    return y\n",
    "\n",
    "# create a random problem with target theta and initial points (x_i, y_i)\n",
    "M, N = 10, 4\n",
    "theta_target = torch.tensor([0.0, -1.0, 0.0, 1.0], device=device).view(N, 1)\n",
    "print(\"Target theta: {}\".format(theta_target.flatten()))\n",
    "\n",
    "X = torch.randn((1, M), device=device)\n",
    "Y = torch.randn((1, M), device=device)\n",
    "\n",
    "fcn = DiffPolyFitFcn.apply\n",
    "theta_init = fcn(X, Y, N)\n",
    "print(\"Initial theta: {}\".format(theta_init.flatten()))\n",
    "\n",
    "# run stochastic gradient descent using the AdamW optimiser for 2000 iterations\n",
    "iters = 2000\n",
    "model = [torch.nn.Parameter(X.clone()), torch.nn.Parameter(Y.clone())]\n",
    "optimizer = torch.optim.AdamW(model, lr=1.0e-2)\n",
    "loss_trace = [None for i in range(iters)]\n",
    "\n",
    "for i in range(len(loss_trace)):\n",
    "    theta = fcn(model[0], model[1], N)    # optimise over both X and Y\n",
    "    #theta = fcn(X.clone(), model[1], N)   # optimise over only Y\n",
    "    #theta = fcn(model[0], Y.clone(), N)   # optimise over only X\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.nn.functional.mse_loss(theta, theta_target)\n",
    "    loss_trace[i] = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Final theta: {}\".format(theta.detach().flatten()))\n",
    "\n",
    "# plot the loss/objective as a function of iterations\n",
    "plt.figure()\n",
    "plt.semilogy(loss_trace)\n",
    "plt.title('Objective Value')\n",
    "plt.show()\n",
    "\n",
    "# plot the initial and final location of points\n",
    "plt.figure()\n",
    "plt.plot(X.flatten(), Y.flatten(), 'r.')\n",
    "plt.plot(model[0].detach().flatten(), model[1].detach().flatten(), 'gx')\n",
    "\n",
    "# plot the target and fitted initial and final polynomials\n",
    "theta = theta.detach().flatten()\n",
    "x = torch.linspace(-2.0, 2.0, 100)\n",
    "\n",
    "plt.plot(x, poly(x, theta_target), 'b-')\n",
    "plt.plot(x, poly(x, theta_init.flatten()), 'r-')\n",
    "plt.plot(x, poly(x, theta), 'g-')\n",
    "\n",
    "plt.title('Polynomial Fit')\n",
    "plt.legend(['initial', 'final', 'target'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Analysis\n",
    "\n",
    "You should observe that the algorithm is able to recover the target parameters but some of the resulting points that have been optimized points $(x_i, y_i)$ do not lie on the curve itself. Provide a short (1-2 sentence) explanation for this. Can you suggest an extension to the method that will recover the correct polynomial curve and have the points closer to the curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
